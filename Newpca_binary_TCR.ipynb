{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Extract_TCR.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyP69nBIZ0M+pIadIYz+X4iD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hereagain-Y/TF_tutorial/blob/main/Newpca_binary_TCR.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "YKtrVJr9OFNj"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.signal import savgol_filter\n",
        "from scipy.spatial import distance\n",
        "\n",
        "from six.moves import xrange\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as transforms\n",
        "import numpy as np\n",
        "\n",
        "from tqdm import tqdm\n",
        "from torchvision.utils import save_image, make_grid\n",
        "from torch.utils.data import DataLoader, Subset\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New section"
      ],
      "metadata": {
        "id": "YTeMzQUlhfvG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XxVcdd1WWpsz",
        "outputId": "f46b45d9-f59a-43fc-a799-addad383707f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "s = []\n",
        "my_file = open(\"/content/drive/My Drive/DL/VAE/Newdata/short_Normal.txt\", \"r\")\n",
        "content_list = my_file.read().splitlines()\n",
        "content_list=np.array(content_list)\n",
        "d= {} # bipphysics dictionary\n",
        "with open(\"/content/drive/My Drive/DL/VAE/AAidx_PCA.txt\") as f:\n",
        "    next(f)\n",
        "    for line in f.readlines():\n",
        "        line=line.strip().split('\\t') #\n",
        "        AA=line[0]\n",
        "        tag=0\n",
        "        values=[]\n",
        "        for PC in line[1:]:\n",
        "            values.append(float(PC))\n",
        "        if tag==1: \n",
        "            continue\n",
        "        d[AA]=values\n",
        "\n",
        "def normalize(d):\n",
        "  result = {}\n",
        "  for key, value in d.items():\n",
        "    maxval = max(d[key])\n",
        "    minval = min(d[key])\n",
        "    newval=[]\n",
        "    for number in value:\n",
        "\n",
        "      newval.append((number-minval)/(maxval-minval))\n",
        "    \n",
        "    result[key] =newval\n",
        "  return(result)\n",
        "\n",
        "d_norm=normalize(d)\n",
        "# new way to normalize \n",
        "data = d.items()\n",
        "list_dat = list(d.values())\n",
        "arr = np.array(list_dat)\n",
        "ex = np.array(arr)\n",
        "ex_norm = (ex-ex.min(axis=0))/(ex.max(axis=0)-ex.min(axis=0))\n",
        "\n",
        "AAs=np.array(list(d.keys()))\n",
        "new_pca = {}\n",
        "\n",
        "for i in np.arange(20):\n",
        "    new_pca[AAs[i]]=ex_norm[i]\n",
        "  \n",
        "# max length\n",
        "#comp_seq=data[\"amino_acid\"].tolist()\n",
        "\n",
        "comp_seq=content_list\n",
        "\n",
        "print(comp_seq)\n",
        "max_len=-1 \n",
        "\n",
        "for AA in comp_seq:\n",
        "    if len(AA)>max_len:\n",
        "        max_len=len(AA)\n",
        "        #res=AA\n",
        "print(max_len )\n",
        "\n",
        "\"\"\"Load AA index data\n",
        "\n",
        "# normalization\n",
        "\"\"\"\n",
        "\n",
        "PC_length=len(d_norm['C'])\n",
        "def AAindexEncoding(Seq):\n",
        "    length_seq=len(Seq)\n",
        "    global max_len\n",
        "    AAE=np.zeros([max_len,15])\n",
        "    if length_seq<max_len:\n",
        "        for amino in range(length_seq):\n",
        "            AA=Seq[amino]# \n",
        "            AAE[amino,]=new_pca[AA] # add PC value \n",
        "            \n",
        "        for amino in range(length_seq,max_len):\n",
        "            AAE[amino,]=np.zeros(15)\n",
        "    else: \n",
        "        for amino in range(length_seq): # zero padding\n",
        "            AA=Seq[amino]# \n",
        "            AAE[amino,]=new_pca[AA]\n",
        "        \n",
        "    #AAE=np.transpose(AAE.astype(np.float32)) # row as PC. and column as AA sequence \n",
        "    return AAE \n",
        "  \n",
        "def GetFeatures(file):\n",
        "    #sequence=file['amino_acid'].tolist()\n",
        "    #sequence=np.array(sequence)\n",
        "    #sequence = file.read().splitlines()\n",
        "    #sequence=np.array(sequence)\n",
        "    hot_encode=[]\n",
        "    for seq in file:\n",
        "        hot_encode.append(AAindexEncoding(seq))\n",
        "    hot_encode=np.array(hot_encode)\n",
        "    result=np.array(hot_encode)\n",
        "    return(result) # dimension: number of sequence [15*length(sequence)]\n",
        "\n",
        "def reconstructSequence(dict,data):\n",
        "  result = []\n",
        "  for i in range(len(data)):\n",
        "    currentSeq= ''\n",
        "    dict_index=list(dict.keys())\n",
        "    if(i%1000==0):\n",
        "      print(str(i/len(data)*100)+'%')\n",
        "    for j in range(len(data[i])):\n",
        "      row = data[i][j]\n",
        "      max_value= np.max(row)\n",
        "      if max_value <= 0.1:\n",
        "        continue\n",
        "      #calculate distance\n",
        "      dist = []\n",
        "      for key, value in dict.items():\n",
        "        dist.append(distance.euclidean(dict[key], row))\n",
        "      currentSeq += dict_index[np.argmin(dist)]\n",
        "    result.append(currentSeq)\n",
        "  return result\n",
        "def CompareSeq(dict,data,correct):\n",
        "  result=[]\n",
        "  result=reconstructSequence(dict,data)\n",
        "  index = 0\n",
        "  print(\"start comparing sequence\")\n",
        "  for i in range(len(result)):\n",
        "    if result[i]==correct[i]:\n",
        "      index += 1\n",
        "  Accu=index/len(result)\n",
        "  print(f'the accuracy is {Accu:.1%}')\n",
        "\n",
        "\n",
        "r1=GetFeatures(content_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4E93kNRzWvBT",
        "outputId": "6ff4bc29-7899-40a0-b296-1595882bd33a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['LKPNTEA' 'AHIANYGY' 'PRPNTEA' ... 'VDVGYEQ' 'LAGQETQ' 'VVPNTEA']\n",
            "13\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "r1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VbDn88QG0xZC",
        "outputId": "165ecb59-e776-4504-f3cb-2204727a7e32"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[0.07030965, 0.40676752, 0.8684857 , ..., 0.50469855,\n",
              "         0.59503819, 0.59367788],\n",
              "        [0.83311257, 0.00431661, 0.5397168 , ..., 0.2385159 ,\n",
              "         0.74577505, 0.35191302],\n",
              "        [0.95036751, 0.87434867, 0.17176543, ..., 0.34823108,\n",
              "         0.48280104, 0.66762789],\n",
              "        ...,\n",
              "        [0.        , 0.        , 0.        , ..., 0.        ,\n",
              "         0.        , 0.        ],\n",
              "        [0.        , 0.        , 0.        , ..., 0.        ,\n",
              "         0.        , 0.        ],\n",
              "        [0.        , 0.        , 0.        , ..., 0.        ,\n",
              "         0.        , 0.        ]],\n",
              "\n",
              "       [[0.50354548, 0.4076369 , 1.        , ..., 0.5111926 ,\n",
              "         0.6006534 , 0.94119758],\n",
              "        [0.5466722 , 0.23034084, 0.23674313, ..., 0.46698353,\n",
              "         0.60350722, 0.57779154],\n",
              "        [0.        , 0.54289831, 0.59825751, ..., 0.        ,\n",
              "         0.327881  , 0.75923615],\n",
              "        ...,\n",
              "        [0.        , 0.        , 0.        , ..., 0.        ,\n",
              "         0.        , 0.        ],\n",
              "        [0.        , 0.        , 0.        , ..., 0.        ,\n",
              "         0.        , 0.        ],\n",
              "        [0.        , 0.        , 0.        , ..., 0.        ,\n",
              "         0.        , 0.        ]],\n",
              "\n",
              "       [[0.95036751, 0.87434867, 0.17176543, ..., 0.34823108,\n",
              "         0.48280104, 0.66762789],\n",
              "        [0.75074501, 0.        , 0.30569116, ..., 0.22308671,\n",
              "         0.41932357, 0.76677   ],\n",
              "        [0.95036751, 0.87434867, 0.17176543, ..., 0.34823108,\n",
              "         0.48280104, 0.66762789],\n",
              "        ...,\n",
              "        [0.        , 0.        , 0.        , ..., 0.        ,\n",
              "         0.        , 0.        ],\n",
              "        [0.        , 0.        , 0.        , ..., 0.        ,\n",
              "         0.        , 0.        ],\n",
              "        [0.        , 0.        , 0.        , ..., 0.        ,\n",
              "         0.        , 0.        ]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[0.11247097, 0.58374741, 0.7162086 , ..., 0.29353891,\n",
              "         0.5001218 , 0.69294201],\n",
              "        [1.        , 0.35242153, 0.45879071, ..., 0.04997744,\n",
              "         1.        , 0.44779209],\n",
              "        [0.11247097, 0.58374741, 0.7162086 , ..., 0.29353891,\n",
              "         0.5001218 , 0.69294201],\n",
              "        ...,\n",
              "        [0.        , 0.        , 0.        , ..., 0.        ,\n",
              "         0.        , 0.        ],\n",
              "        [0.        , 0.        , 0.        , ..., 0.        ,\n",
              "         0.        , 0.        ],\n",
              "        [0.        , 0.        , 0.        , ..., 0.        ,\n",
              "         0.        , 0.        ]],\n",
              "\n",
              "       [[0.07030965, 0.40676752, 0.8684857 , ..., 0.50469855,\n",
              "         0.59503819, 0.59367788],\n",
              "        [0.50354548, 0.4076369 , 1.        , ..., 0.5111926 ,\n",
              "         0.6006534 , 0.94119758],\n",
              "        [0.9145489 , 1.        , 0.6684107 , ..., 0.43914286,\n",
              "         0.41429701, 0.48426866],\n",
              "        ...,\n",
              "        [0.        , 0.        , 0.        , ..., 0.        ,\n",
              "         0.        , 0.        ],\n",
              "        [0.        , 0.        , 0.        , ..., 0.        ,\n",
              "         0.        , 0.        ],\n",
              "        [0.        , 0.        , 0.        , ..., 0.        ,\n",
              "         0.        , 0.        ]],\n",
              "\n",
              "       [[0.11247097, 0.58374741, 0.7162086 , ..., 0.29353891,\n",
              "         0.5001218 , 0.69294201],\n",
              "        [0.11247097, 0.58374741, 0.7162086 , ..., 0.29353891,\n",
              "         0.5001218 , 0.69294201],\n",
              "        [0.95036751, 0.87434867, 0.17176543, ..., 0.34823108,\n",
              "         0.48280104, 0.66762789],\n",
              "        ...,\n",
              "        [0.        , 0.        , 0.        , ..., 0.        ,\n",
              "         0.        , 0.        ],\n",
              "        [0.        , 0.        , 0.        , ..., 0.        ,\n",
              "         0.        , 0.        ],\n",
              "        [0.        , 0.        , 0.        , ..., 0.        ,\n",
              "         0.        , 0.        ]]])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "kwargs = {'num_workers': 1, 'pin_memory': True} \n",
        "r1_transform=torch.from_numpy(r1) # from np to tensor\n",
        "r1_transform=r1_transform.float()\n",
        "r1_transform.shape\n",
        "train_ds, test_ds =torch.utils.data.random_split(r1_transform, (int(0.8*len(r1_transform)), len(r1_transform)-int(0.8*len(r1_transform))))\n",
        "print(train_ds, test_ds)\n",
        "\n",
        "train_loader = DataLoader(dataset=train_ds, batch_size=1000)\n",
        "test_loader  = DataLoader(dataset=test_ds,  batch_size=1000)\n",
        "cuda = True\n",
        "DEVICE = torch.device(\"cuda\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OGf5Q_nlXSdh",
        "outputId": "07a65aaf-98a7-4e12-c01e-a33e954d8545"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<torch.utils.data.dataset.Subset object at 0x7fe5bebbc690> <torch.utils.data.dataset.Subset object at 0x7fe5bebbc390>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#change parameter \n",
        "batch_size = 1000\n",
        "x_dim= 195#660 # 44*15\n",
        "#hidden_dim = 256\n",
        "\n",
        "latent_dim = 128\n",
        "lr = 1e-3"
      ],
      "metadata": {
        "id": "pRSxlUpHXXtP"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 10000\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    \n",
        "    def __init__(self, input_dim, latent_dim):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.hsize = int(1.5*input_dim)\n",
        "        self.FC_input = nn.Linear(input_dim, self.hsize)\n",
        "        self.FC_input1 = nn.Linear(self.hsize, self.hsize)\n",
        "        #self.FC_input2 = nn.Linear(hidden_dim, hidden_dim)\n",
        "        #self.FC_input3 = nn.Linear(hidden_dim, hidden_dim2)\n",
        "        self.FC_mean  = nn.Linear(self.hsize, latent_dim)\n",
        "        self.FC_var   = nn.Linear (self.hsize, latent_dim)\n",
        "        self.relu = nn.ReLU()  \n",
        "        self.dropout1= nn.Dropout(p=0.3)\n",
        "        self.dropout2 = nn.Dropout(p=0.3)     \n",
        "        self.training = True\n",
        "        \n",
        "    def forward(self, x):\n",
        "        h_       = self.relu(self.FC_input(x))\n",
        "        h_       = self.dropout1(h_)\n",
        "        h_       = self.relu(self.FC_input1(h_))\n",
        "        #h_       = self.dropout1(h_)\n",
        "        #h_       = self.relu(self.FC_input2(h_))\n",
        "        #h_       = self.relu(self.FC_input3(h_))\n",
        "        mean     = self.FC_mean(h_)\n",
        "        log_var  = self.FC_var(h_)                     # encoder produces mean and log of variance \n",
        "                                                     #             (i.e., parateters of simple tractable normal distribution \"q\"\n",
        "        \n",
        "        return mean, log_var\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, latent_dim,output_dim):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.hsize = int(1.5*output_dim)\n",
        "        self.FC_hidden1 = nn.Linear(latent_dim, self.hsize)\n",
        "        #self.FC_hidden3 = nn.Linear(hidden_dim, hidden_dim)\n",
        "        self.FC_hidden2 = nn.Linear(self.hsize, self.hsize)\n",
        "        #self.FC_hidden = nn.Linear(hidden_dim, self.hsize)\n",
        "        self.FC_output = nn.Linear(self.hsize, output_dim)      \n",
        "        self.relu = nn.ReLU()\n",
        "        self.dropout1= nn.Dropout(p=0.3)\n",
        "       # self.dropout2 = nn.Dropout(p=0.3)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        h     = self.relu(self.FC_hidden1(x))\n",
        "        h     = self.dropout1(h)\n",
        "        #h     = self.relu(self.FC_hidden3(h))\n",
        "        h     = self.relu(self.FC_hidden2(h))\n",
        "        #h     = self.dropout1(h)\n",
        "        #h     = self.relu(self.FC_hidden(h))\n",
        "        x_hat = torch.sigmoid(self.FC_output(h))\n",
        "        #x_hat = self.relu(self.FC_output(h))\n",
        "        return x_hat\n",
        "\n",
        "class Model(nn.Module):\n",
        "    def __init__(self, Encoder, Decoder):\n",
        "        super(Model, self).__init__()\n",
        "        self.Encoder = Encoder\n",
        "        self.Decoder = Decoder\n",
        "        \n",
        "    def reparameterization(self, mean, var):\n",
        "        epsilon = torch.randn_like(var).to(DEVICE)        # sampling epsilon        \n",
        "        z = mean + var*epsilon \n",
        "        #z  = mean                       # reparameterization trick\n",
        "        return z\n",
        "        \n",
        "                \n",
        "    def forward(self, x):\n",
        "        mean, log_var = self.Encoder(x)\n",
        "        z = self.reparameterization(mean, torch.exp(0.5 * log_var)) # takes exponential function (log var -> var) ]\n",
        "        x_hat = self.Decoder(z)\n",
        "        \n",
        "        return x_hat, mean, log_var\n",
        "\n",
        "encoder = Encoder(input_dim=x_dim, latent_dim=latent_dim)\n",
        "decoder = Decoder(latent_dim=latent_dim,output_dim = x_dim)\n",
        "\n",
        "model = Model(Encoder=encoder, Decoder=decoder).to(DEVICE)\n",
        "\n",
        "from torch.optim import Adam\n",
        "\n",
        "BCE_loss = nn.BCELoss()\n",
        "\n",
        "def loss_function(x, x_hat, mean, log_var):\n",
        "    reproduction_loss = nn.functional.binary_cross_entropy(x_hat, x, reduction='sum')\n",
        "    #MSELoss_criterion = nn.MSELoss()\n",
        "    #reproduction_loss = MSELoss_criterion(x_hat, x) \n",
        "    # try MSE \n",
        "    #MSELoss_criterion = nn.MSELoss()\n",
        "    #reproduction_loss = MSELoss_criterion(x_hat, x) \n",
        "    KLD      = - 0.5 * torch.sum(1+ log_var - mean.pow(2) - log_var.exp())\n",
        "    return reproduction_loss + KLD, reproduction_loss\n",
        "\n",
        "\n",
        "optimizer = Adam(model.parameters(), lr=lr)   \n",
        "\n",
        "train_loss= [] # before epoch\n",
        "testtoal_loss= []\n",
        "reproduction1=[]\n",
        "reproduction2=[]\n",
        "\n",
        "def plotCurve(x_vals,y_vals,x_label, y_label,\n",
        "              x2_vals=None, y2_vals=None, legend=None,figsize=(3.5,2.5)):\n",
        "    plt.xlabel(x_label)\n",
        "    plt.ylabel(y_label)\n",
        "    plt.semilogy(x_vals, y_vals)\n",
        "    if x2_vals and y2_vals:\n",
        "        plt.semilogy(x2_vals, y2_vals, linestyle=':')\n",
        "    \n",
        "    if legend:\n",
        "        plt.legend(legend)\n",
        "for epoch in range(epochs):\n",
        "    overall_loss = 0\n",
        "    overall_testloss= 0\n",
        "    overall_res = 0\n",
        "    overall_testres= 0\n",
        "    \n",
        "    for batch_idx, x in enumerate(train_loader):\n",
        "        x = x.view(len(x), x_dim)\n",
        "        x = x.to(DEVICE)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        x_hat, mean, log_var = model(x)\n",
        "        loss, reproduction_loss = loss_function(x, x_hat, mean, log_var)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        overall_loss += loss.item()\n",
        "        overall_res += reproduction_loss.item()\n",
        "    train_loss.append(overall_loss/len(train_ds))\n",
        "    reproduction1.append(overall_res/len(train_ds))\n",
        "\n",
        "      #test loss\n",
        "    for batch_idx, x in enumerate(test_loader):\n",
        "        x = x.view(len(x), x_dim)\n",
        "        x = x.to(DEVICE)\n",
        "\n",
        "        #optimizer.zero_grad()\n",
        "\n",
        "        pred, mean, log_var = model(x)\n",
        "        test_loss, test_reproduction= loss_function(x, pred, mean, log_var)\n",
        "        overall_testloss += test_loss.item()\n",
        "        overall_testres += test_reproduction.item()\n",
        "    testtoal_loss.append(overall_testloss/len(test_ds))\n",
        "    reproduction2.append(overall_testres/len(test_ds))\n",
        "\n",
        "    if (epoch % 100 == 0):\n",
        "      #print('====> Epoch %d done! Average Loss:  = %.2e, Average test loss = %.2e' % (epoch,overall_loss / (batch_idx*batch_size),overall_testloss/(batch_idx*batch_size)))\n",
        "        \n",
        "        \n",
        "      print(\"\\tEpoch\", epoch , \"complete!\", \"\\tAverage Loss: \", train_loss[epoch],#overall_loss / (batch_idx*batch_size),\n",
        "        \"\\tAverage Test Loss: \" , testtoal_loss[epoch])\n",
        "    \n",
        "print(\"Finish!!\")\n",
        "print(\"plot curves\")\n",
        "plotCurve(range(1,epochs+1),train_loss,\"epoch\",\"loss\",\n",
        "          range(1,epochs+1),testtoal_loss,\n",
        "          ['train','test'])\n",
        "\n",
        "\n",
        "print('==train end===')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "IKqa5QIXXeVs",
        "outputId": "d264c073-75f4-40c0-fdfa-a334aa05616c"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tEpoch 0 complete! \tAverage Loss:  101.27676318359374 \tAverage Test Loss:  89.474712890625\n",
            "\tEpoch 100 complete! \tAverage Loss:  79.4108779296875 \tAverage Test Loss:  79.44004296875\n",
            "\tEpoch 200 complete! \tAverage Loss:  78.69944360351562 \tAverage Test Loss:  78.7359345703125\n",
            "\tEpoch 300 complete! \tAverage Loss:  78.197095703125 \tAverage Test Loss:  78.228587890625\n",
            "\tEpoch 400 complete! \tAverage Loss:  77.96493603515626 \tAverage Test Loss:  78.0150869140625\n",
            "\tEpoch 500 complete! \tAverage Loss:  77.85914013671875 \tAverage Test Loss:  77.868400390625\n",
            "\tEpoch 600 complete! \tAverage Loss:  77.74202368164063 \tAverage Test Loss:  77.8550751953125\n",
            "\tEpoch 700 complete! \tAverage Loss:  77.67153686523437 \tAverage Test Loss:  77.788365234375\n",
            "\tEpoch 800 complete! \tAverage Loss:  77.66088427734375 \tAverage Test Loss:  77.7152978515625\n",
            "\tEpoch 900 complete! \tAverage Loss:  77.61592797851563 \tAverage Test Loss:  77.6784150390625\n",
            "\tEpoch 1000 complete! \tAverage Loss:  77.59510180664063 \tAverage Test Loss:  77.654599609375\n",
            "\tEpoch 1100 complete! \tAverage Loss:  77.58178295898438 \tAverage Test Loss:  77.6383154296875\n",
            "\tEpoch 1200 complete! \tAverage Loss:  77.62275756835938 \tAverage Test Loss:  77.6604677734375\n",
            "\tEpoch 1300 complete! \tAverage Loss:  77.603509765625 \tAverage Test Loss:  77.6404423828125\n",
            "\tEpoch 1400 complete! \tAverage Loss:  77.60361328125 \tAverage Test Loss:  77.65275\n",
            "\tEpoch 1500 complete! \tAverage Loss:  77.58113452148437 \tAverage Test Loss:  77.5487392578125\n",
            "\tEpoch 1600 complete! \tAverage Loss:  77.53556103515625 \tAverage Test Loss:  77.549751953125\n",
            "\tEpoch 1700 complete! \tAverage Loss:  77.504333984375 \tAverage Test Loss:  77.55993359375\n",
            "\tEpoch 1800 complete! \tAverage Loss:  77.59766088867187 \tAverage Test Loss:  77.69219921875\n",
            "\tEpoch 1900 complete! \tAverage Loss:  77.53581201171875 \tAverage Test Loss:  77.5688115234375\n",
            "\tEpoch 2000 complete! \tAverage Loss:  77.51078857421875 \tAverage Test Loss:  77.5577412109375\n",
            "\tEpoch 2100 complete! \tAverage Loss:  77.47035986328125 \tAverage Test Loss:  77.548884765625\n",
            "\tEpoch 2200 complete! \tAverage Loss:  77.48317602539062 \tAverage Test Loss:  77.554486328125\n",
            "\tEpoch 2300 complete! \tAverage Loss:  77.50260278320313 \tAverage Test Loss:  77.5956279296875\n",
            "\tEpoch 2400 complete! \tAverage Loss:  77.49063305664062 \tAverage Test Loss:  77.52195703125\n",
            "\tEpoch 2500 complete! \tAverage Loss:  77.41314892578124 \tAverage Test Loss:  77.461421875\n",
            "\tEpoch 2600 complete! \tAverage Loss:  77.41520727539063 \tAverage Test Loss:  77.490484375\n",
            "\tEpoch 2700 complete! \tAverage Loss:  77.41938793945313 \tAverage Test Loss:  77.452189453125\n",
            "\tEpoch 2800 complete! \tAverage Loss:  77.42236645507812 \tAverage Test Loss:  77.504447265625\n",
            "\tEpoch 2900 complete! \tAverage Loss:  77.40273217773438 \tAverage Test Loss:  77.5293564453125\n",
            "\tEpoch 3000 complete! \tAverage Loss:  77.42075341796875 \tAverage Test Loss:  77.5230458984375\n",
            "\tEpoch 3100 complete! \tAverage Loss:  77.45656005859375 \tAverage Test Loss:  77.512017578125\n",
            "\tEpoch 3200 complete! \tAverage Loss:  77.4255654296875 \tAverage Test Loss:  77.4484736328125\n",
            "\tEpoch 3300 complete! \tAverage Loss:  77.39150390625 \tAverage Test Loss:  77.4365087890625\n",
            "\tEpoch 3400 complete! \tAverage Loss:  77.38144702148438 \tAverage Test Loss:  77.5175810546875\n",
            "\tEpoch 3500 complete! \tAverage Loss:  77.40268896484375 \tAverage Test Loss:  77.461666015625\n",
            "\tEpoch 3600 complete! \tAverage Loss:  77.3987578125 \tAverage Test Loss:  77.5046669921875\n",
            "\tEpoch 3700 complete! \tAverage Loss:  77.35816943359374 \tAverage Test Loss:  77.4231923828125\n",
            "\tEpoch 3800 complete! \tAverage Loss:  77.35986938476563 \tAverage Test Loss:  77.39626953125\n",
            "\tEpoch 3900 complete! \tAverage Loss:  77.43588916015625 \tAverage Test Loss:  77.5070185546875\n",
            "\tEpoch 4000 complete! \tAverage Loss:  77.40346875 \tAverage Test Loss:  77.474306640625\n",
            "\tEpoch 4100 complete! \tAverage Loss:  77.36728979492187 \tAverage Test Loss:  77.4673876953125\n",
            "\tEpoch 4200 complete! \tAverage Loss:  77.451171875 \tAverage Test Loss:  77.5179072265625\n",
            "\tEpoch 4300 complete! \tAverage Loss:  77.41123803710937 \tAverage Test Loss:  77.5171337890625\n",
            "\tEpoch 4400 complete! \tAverage Loss:  77.41673706054688 \tAverage Test Loss:  77.5815703125\n",
            "\tEpoch 4500 complete! \tAverage Loss:  77.35960766601562 \tAverage Test Loss:  77.42509765625\n",
            "\tEpoch 4600 complete! \tAverage Loss:  77.3784326171875 \tAverage Test Loss:  77.44641015625\n",
            "\tEpoch 4700 complete! \tAverage Loss:  77.4434443359375 \tAverage Test Loss:  77.5237900390625\n",
            "\tEpoch 4800 complete! \tAverage Loss:  77.41874780273437 \tAverage Test Loss:  77.440982421875\n",
            "\tEpoch 4900 complete! \tAverage Loss:  77.39809521484375 \tAverage Test Loss:  77.4700478515625\n",
            "\tEpoch 5000 complete! \tAverage Loss:  77.37787353515625 \tAverage Test Loss:  77.4228388671875\n",
            "\tEpoch 5100 complete! \tAverage Loss:  77.37492407226563 \tAverage Test Loss:  77.4501357421875\n",
            "\tEpoch 5200 complete! \tAverage Loss:  77.39112841796874 \tAverage Test Loss:  77.4586923828125\n",
            "\tEpoch 5300 complete! \tAverage Loss:  77.33795166015625 \tAverage Test Loss:  77.4552607421875\n",
            "\tEpoch 5400 complete! \tAverage Loss:  77.37110034179688 \tAverage Test Loss:  77.4606279296875\n",
            "\tEpoch 5500 complete! \tAverage Loss:  77.34020043945313 \tAverage Test Loss:  77.3916259765625\n",
            "\tEpoch 5600 complete! \tAverage Loss:  77.35633959960937 \tAverage Test Loss:  77.4306328125\n",
            "\tEpoch 5700 complete! \tAverage Loss:  77.36418896484375 \tAverage Test Loss:  77.4206357421875\n",
            "\tEpoch 5800 complete! \tAverage Loss:  77.34413891601562 \tAverage Test Loss:  77.4224990234375\n",
            "\tEpoch 5900 complete! \tAverage Loss:  77.38959838867187 \tAverage Test Loss:  77.5356142578125\n",
            "\tEpoch 6000 complete! \tAverage Loss:  77.4747734375 \tAverage Test Loss:  77.6276435546875\n",
            "\tEpoch 6100 complete! \tAverage Loss:  77.35764965820313 \tAverage Test Loss:  77.463201171875\n",
            "\tEpoch 6200 complete! \tAverage Loss:  77.37562231445312 \tAverage Test Loss:  77.381904296875\n",
            "\tEpoch 6300 complete! \tAverage Loss:  77.4012216796875 \tAverage Test Loss:  77.4491455078125\n",
            "\tEpoch 6400 complete! \tAverage Loss:  77.34895068359376 \tAverage Test Loss:  77.4839326171875\n",
            "\tEpoch 6500 complete! \tAverage Loss:  77.38180102539063 \tAverage Test Loss:  77.3943193359375\n",
            "\tEpoch 6600 complete! \tAverage Loss:  77.357341796875 \tAverage Test Loss:  77.4418115234375\n",
            "\tEpoch 6700 complete! \tAverage Loss:  77.35862719726562 \tAverage Test Loss:  77.386361328125\n",
            "\tEpoch 6800 complete! \tAverage Loss:  77.30188671875 \tAverage Test Loss:  77.3764169921875\n",
            "\tEpoch 6900 complete! \tAverage Loss:  77.37220825195313 \tAverage Test Loss:  77.416673828125\n",
            "\tEpoch 7000 complete! \tAverage Loss:  77.3063505859375 \tAverage Test Loss:  77.4361611328125\n",
            "\tEpoch 7100 complete! \tAverage Loss:  77.33017236328125 \tAverage Test Loss:  77.3699677734375\n",
            "\tEpoch 7200 complete! \tAverage Loss:  77.31122998046875 \tAverage Test Loss:  77.3362978515625\n",
            "\tEpoch 7300 complete! \tAverage Loss:  77.33563671875 \tAverage Test Loss:  77.3379296875\n",
            "\tEpoch 7400 complete! \tAverage Loss:  77.3163154296875 \tAverage Test Loss:  77.3749521484375\n",
            "\tEpoch 7500 complete! \tAverage Loss:  77.29564038085938 \tAverage Test Loss:  77.3347734375\n",
            "\tEpoch 7600 complete! \tAverage Loss:  77.30420556640625 \tAverage Test Loss:  77.505755859375\n",
            "\tEpoch 7700 complete! \tAverage Loss:  77.34489404296875 \tAverage Test Loss:  77.380171875\n",
            "\tEpoch 7800 complete! \tAverage Loss:  77.31520483398438 \tAverage Test Loss:  77.3932880859375\n",
            "\tEpoch 7900 complete! \tAverage Loss:  77.3292607421875 \tAverage Test Loss:  77.4482119140625\n",
            "\tEpoch 8000 complete! \tAverage Loss:  77.34960620117188 \tAverage Test Loss:  77.4686513671875\n",
            "\tEpoch 8100 complete! \tAverage Loss:  77.35331616210938 \tAverage Test Loss:  77.40369140625\n",
            "\tEpoch 8200 complete! \tAverage Loss:  77.33570849609374 \tAverage Test Loss:  77.3700107421875\n",
            "\tEpoch 8300 complete! \tAverage Loss:  77.33472338867188 \tAverage Test Loss:  77.4656513671875\n",
            "\tEpoch 8400 complete! \tAverage Loss:  77.314546875 \tAverage Test Loss:  77.362421875\n",
            "\tEpoch 8500 complete! \tAverage Loss:  77.298638671875 \tAverage Test Loss:  77.3202578125\n",
            "\tEpoch 8600 complete! \tAverage Loss:  77.3329775390625 \tAverage Test Loss:  77.3726943359375\n",
            "\tEpoch 8700 complete! \tAverage Loss:  77.30420776367187 \tAverage Test Loss:  77.3695712890625\n",
            "\tEpoch 8800 complete! \tAverage Loss:  77.37520458984375 \tAverage Test Loss:  77.471951171875\n",
            "\tEpoch 8900 complete! \tAverage Loss:  77.37825732421875 \tAverage Test Loss:  77.4843564453125\n",
            "\tEpoch 9000 complete! \tAverage Loss:  77.3649384765625 \tAverage Test Loss:  77.4392255859375\n",
            "\tEpoch 9100 complete! \tAverage Loss:  77.32497607421875 \tAverage Test Loss:  77.3857890625\n",
            "\tEpoch 9200 complete! \tAverage Loss:  77.33836303710937 \tAverage Test Loss:  77.5649990234375\n",
            "\tEpoch 9300 complete! \tAverage Loss:  77.42924267578125 \tAverage Test Loss:  77.4114365234375\n",
            "\tEpoch 9400 complete! \tAverage Loss:  77.340447265625 \tAverage Test Loss:  77.456716796875\n",
            "\tEpoch 9500 complete! \tAverage Loss:  77.38566015625 \tAverage Test Loss:  77.4522666015625\n",
            "\tEpoch 9600 complete! \tAverage Loss:  77.35154248046875 \tAverage Test Loss:  77.448025390625\n",
            "\tEpoch 9700 complete! \tAverage Loss:  77.40179663085938 \tAverage Test Loss:  77.48514453125\n",
            "\tEpoch 9800 complete! \tAverage Loss:  77.32714038085938 \tAverage Test Loss:  77.484025390625\n",
            "\tEpoch 9900 complete! \tAverage Loss:  77.41103295898438 \tAverage Test Loss:  77.506732421875\n",
            "Finish!!\n",
            "plot curves\n",
            "==train end===\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model, '/content/drive/My Drive/DL/VAE/Newdata/VAE_extract_modify_Binary_model_1000_echo.apx')\n",
        "model = torch.load('/content/drive/My Drive/DL/VAE/Newdata/VAE_extract_modify_Binary_model_1000_echo.apx')"
      ],
      "metadata": {
        "id": "ErrdaPi0esko"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "my_file2 = open(\"/content/drive/My Drive/DL/VAE/Newdata/short_Normaltest.txt\", \"r\")\n",
        "content_list2 = my_file2.read().splitlines()\n",
        "\n",
        "neww=np.array(content_list2)\n",
        "\n",
        "#neww=[x for x in content_list2 if len(x)<=13]\n",
        "\n",
        "neww=np.array(neww)\n",
        "r2=GetFeatures(neww)\n",
        "r2_transform=torch.from_numpy(r2).float() # change to tensor and float \n",
        "m2=r2_transform.view(len(r2_transform),195) # flatten \n",
        "#m2 = torch.from_numpy(m2).float()\n",
        "#result = model(m2)[0] # \n",
        "result = model(m2.cuda())[0]\n",
        "result2 = result.view( len(result),13,15 ).cpu().detach().numpy()\n",
        "\n",
        "\n",
        "seq_decode=reconstructSequence(new_pca,result2)\n",
        "#content_list2\n",
        "seq_decode[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DtaEeXyJe1K0",
        "outputId": "dc72743f-508d-4cbc-8dfc-0ecc33aa7c36"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.0%\n",
            "5.037529595486374%\n",
            "10.075059190972748%\n",
            "15.112588786459119%\n",
            "20.150118381945497%\n",
            "25.187647977431865%\n",
            "30.225177572918238%\n",
            "35.26270716840462%\n",
            "40.30023676389099%\n",
            "45.33776635937736%\n",
            "50.37529595486373%\n",
            "55.41282555035011%\n",
            "60.450355145836475%\n",
            "65.48788474132286%\n",
            "70.52541433680923%\n",
            "75.5629439322956%\n",
            "80.60047352778199%\n",
            "85.63800312326835%\n",
            "90.67553271875472%\n",
            "95.7130623142411%\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['LGSAGSTDTQ',\n",
              " 'AGSAGSTDTQ',\n",
              " 'AGSAGSTDTQ',\n",
              " 'QSSGGSTDTQ',\n",
              " 'QSSGGGTDTQ',\n",
              " 'QSSGSSSDTQ',\n",
              " 'QSSGGSTDTQ',\n",
              " 'QSSGGGSDTQ',\n",
              " 'AGSSGGQETQ',\n",
              " 'AGSSGGQETQ']"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "neww[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9u6l49yCfcYA",
        "outputId": "3a1a9ca0-3038-4c1b-fa20-714b888fe657"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['RGTSASTDTQ', 'QEFAGGTDTQ', 'QDFGGGTDTQ', 'QDRGQGADTQ',\n",
              "       'QDPGQGADTQ', 'QEPGQGSDTQ', 'QEPGQGADTQ', 'QDPGGGADTQ',\n",
              "       'QDPSGGAETQ', 'QDNSGGAETQ'], dtype='<U13')"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "seq_decode[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lDBJV2Fd9rOG",
        "outputId": "e24c8c96-641f-40c5-be07-64283d532840"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['QSSSGGTDTQ',\n",
              " 'QSSAGGTDTQ',\n",
              " 'QSAGGSTDTQ',\n",
              " 'QSSGGSTDTQ',\n",
              " 'QSAGGGTDTQ',\n",
              " 'QSASGGSDTQ',\n",
              " 'QSSAGGTDTQ',\n",
              " 'QSSGGGTDTQ',\n",
              " 'AGAGGGQETQ',\n",
              " 'QSSSGGSDTQ']"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "CompareSeq(new_pca,result2,neww)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bYhYaFu8e5ML",
        "outputId": "2cc972dd-4c10-415e-949c-3bdb7e2ae964"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.0%\n",
            "5.037529595486374%\n",
            "10.075059190972748%\n",
            "15.112588786459119%\n",
            "20.150118381945497%\n",
            "25.187647977431865%\n",
            "30.225177572918238%\n",
            "35.26270716840462%\n",
            "40.30023676389099%\n",
            "45.33776635937736%\n",
            "50.37529595486373%\n",
            "55.41282555035011%\n",
            "60.450355145836475%\n",
            "65.48788474132286%\n",
            "70.52541433680923%\n",
            "75.5629439322956%\n",
            "80.60047352778199%\n",
            "85.63800312326835%\n",
            "90.67553271875472%\n",
            "95.7130623142411%\n",
            "start comparing sequence\n",
            "the accuracy is 0.1%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a= neww[3]\n",
        "b= seq_decode[3]"
      ],
      "metadata": {
        "id": "U6KoMvU3-AQk"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(seq_decode)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kiYLCQ5ugfok",
        "outputId": "3061854e-4129-4f41-aed4-2a26872437bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10000"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(content_list2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hg8tWYH7gh3w",
        "outputId": "3ba4a799-abd5-418e-dbc9-6ecff1362150"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10000"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "kjO5gW4C-bTO",
        "outputId": "eb559386-20ff-43c4-8753-d8090766c7bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'IRNPETQ'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "b"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "5LP79SWZ_Flg",
        "outputId": "0b01b760-cd67-4aba-d7dc-a739d2cb27db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'PSGSETQ'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def compare_percent (seq1,seq2):\n",
        "  return float(sum(seq1[i]==seq2[i] for i in range(len(seq1)))/len(seq1))"
      ],
      "metadata": {
        "id": "dh2V0t8m-Gt7"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "compare_percent(seq_decode[1],neww[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yzDEPNSkAYct",
        "outputId": "e91fc732-a0c6-45a3-93f5-1a04fad2be22"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def compare_percent (seq1,seq2):\n",
        "  return float(sum(seq1[i]==seq2[i] for i in range(len(seq1)))/len(seq1))\n",
        "\n",
        "def CoverageSeq(data,correct):\n",
        "  print(\"start comparing sequence\")\n",
        "  percentage = []\n",
        "  for i in range(len(data)):\n",
        "    percentage.append(compare_percent(data[i],correct[i]))\n",
        "  Accu = sum(percentage)/len(percentage)   \n",
        "  print(f'the average coverage is {Accu:.1%}')\n",
        "\n",
        " \n",
        "  "
      ],
      "metadata": {
        "id": "4MpgzQtY-_NH"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(r'/content/drive/My Drive/DL/VAE/Newdata/Tumor_prediction.txt','w') as fp:\n",
        "    fp.write('\\n'.join(seq_decode))"
      ],
      "metadata": {
        "id": "LUEzwobJfcL-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "CoverageSeq(seq_decode[:50],neww[:50])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xjtSDiwoAEcX",
        "outputId": "c47caf61-6ab8-4a70-9bde-ffe14a9e3ff2"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "start comparing sequence\n",
            "the average coverage is 59.4%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "S0Kx2flU49BI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "new_pca"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SXv_zgVF49js",
        "outputId": "820946b3-25e9-4521-c6b7-25ce85081aea"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'A': array([0.50354548, 0.4076369 , 1.        , 0.55951449, 0.73118242,\n",
              "        0.43092049, 0.78203872, 0.36312716, 0.63041598, 0.2458337 ,\n",
              "        0.51973429, 0.43396146, 0.5111926 , 0.6006534 , 0.94119758]),\n",
              " 'C': array([0.31121817, 0.66882902, 0.24303985, 1.        , 1.        ,\n",
              "        1.        , 0.6498213 , 0.11758461, 0.28151378, 0.70761651,\n",
              "        0.63877004, 0.59669379, 0.48222483, 0.47926492, 0.55233719]),\n",
              " 'D': array([1.        , 0.35242153, 0.45879071, 0.64595929, 0.88531876,\n",
              "        0.21007324, 0.        , 0.37649839, 0.18366252, 0.31832004,\n",
              "        0.57289266, 0.67644312, 0.04997744, 1.        , 0.44779209]),\n",
              " 'E': array([0.84156162, 0.01472165, 0.74788582, 0.50782993, 0.99378639,\n",
              "        0.36414319, 0.28450833, 0.24629134, 0.13982815, 0.39741824,\n",
              "        0.44123645, 0.3951055 , 0.72998689, 0.07643977, 0.64214071]),\n",
              " 'F': array([0.0453665 , 0.4453626 , 0.35492999, 0.49786522, 0.49910808,\n",
              "        0.2526996 , 0.54564697, 0.58228714, 0.27279403, 0.30506733,\n",
              "        0.70382136, 0.72145279, 0.40878165, 0.18731579, 0.        ]),\n",
              " 'G': array([0.9145489 , 1.        , 0.6684107 , 0.74867381, 0.20191558,\n",
              "        0.        , 0.928923  , 0.11158769, 0.        , 0.29856743,\n",
              "        0.35444229, 0.52654872, 0.43914286, 0.41429701, 0.48426866]),\n",
              " 'H': array([0.5466722 , 0.23034084, 0.23674313, 0.69599783, 0.59789787,\n",
              "        0.44526773, 0.86640268, 1.        , 0.09437858, 0.29780476,\n",
              "        0.6117088 , 0.        , 0.46698353, 0.60350722, 0.57779154]),\n",
              " 'I': array([0.        , 0.54289831, 0.59825751, 0.4708124 , 0.36962036,\n",
              "        0.55140923, 0.31640025, 0.46181541, 0.06907555, 0.533935  ,\n",
              "        0.22090039, 0.48720571, 0.        , 0.327881  , 0.75923615]),\n",
              " 'K': array([0.83311257, 0.00431661, 0.5397168 , 0.51335308, 0.17080672,\n",
              "        0.51651729, 0.84397111, 0.314569  , 0.49219165, 1.        ,\n",
              "        0.23670444, 0.45174757, 0.2385159 , 0.74577505, 0.35191302]),\n",
              " 'L': array([0.07030965, 0.40676752, 0.8684857 , 0.41046604, 0.45989152,\n",
              "        0.36670608, 0.62397351, 0.45830058, 0.5529443 , 0.68610625,\n",
              "        1.        , 0.76046812, 0.50469855, 0.59503819, 0.59367788]),\n",
              " 'M': array([0.12333395, 0.24346866, 0.50313421, 0.63101795, 0.89242261,\n",
              "        0.4071863 , 1.        , 0.60823494, 0.20075653, 0.15877156,\n",
              "        0.14918934, 1.        , 0.21593719, 0.70353792, 0.76815994]),\n",
              " 'N': array([0.91534314, 0.46498996, 0.34456904, 0.74773478, 0.42531884,\n",
              "        0.2776711 , 0.48026122, 0.77929179, 0.444165  , 0.69032909,\n",
              "        0.60590039, 0.7491068 , 0.0691919 , 0.        , 1.        ]),\n",
              " 'P': array([0.95036751, 0.87434867, 0.17176543, 0.        , 0.8820364 ,\n",
              "        0.71827252, 0.76136545, 0.43366677, 0.30902513, 0.45718374,\n",
              "        0.48978171, 0.55937743, 0.34823108, 0.48280104, 0.66762789]),\n",
              " 'Q': array([0.73470404, 0.15413173, 0.44710621, 0.57572548, 0.57560045,\n",
              "        0.61084758, 0.64210614, 0.45661582, 0.43004342, 0.40960816,\n",
              "        0.        , 0.8571629 , 0.58638868, 0.22637819, 0.4562345 ]),\n",
              " 'R': array([0.75074501, 0.        , 0.30569116, 0.53943379, 0.        ,\n",
              "        0.8382432 , 0.69481432, 0.08361831, 0.1106684 , 0.        ,\n",
              "        0.8625434 , 0.68965372, 0.22308671, 0.41932357, 0.76677   ]),\n",
              " 'S': array([0.83691199, 0.62587895, 0.56787507, 0.68624476, 0.36429031,\n",
              "        0.59783729, 0.48701846, 0.6419868 , 0.91526777, 0.34459209,\n",
              "        0.5160937 , 0.65589048, 0.49694967, 0.58137626, 0.73076975]),\n",
              " 'T': array([0.64655608, 0.57265116, 0.51599322, 0.62926071, 0.33621006,\n",
              "        0.75491801, 0.360507  , 0.56840305, 0.93827579, 0.07907109,\n",
              "        0.30356047, 0.52375941, 0.40037662, 0.45485839, 0.30691402]),\n",
              " 'V': array([0.11247097, 0.58374741, 0.7162086 , 0.5532744 , 0.30086503,\n",
              "        0.77449216, 0.27495057, 0.39388225, 0.13310144, 0.36295439,\n",
              "        0.23154801, 0.30211069, 0.29353891, 0.5001218 , 0.69294201]),\n",
              " 'W': array([0.10510695, 0.29912515, 0.        , 0.54927228, 0.6532478 ,\n",
              "        0.04017657, 0.6019156 , 0.        , 1.        , 0.32890699,\n",
              "        0.38188638, 0.31161021, 0.22370837, 0.40379493, 0.75077026]),\n",
              " 'Y': array([0.33383287, 0.45710052, 0.05809713, 0.53953891, 0.14235009,\n",
              "        0.29899305, 0.26697424, 0.46869028, 0.15290173, 0.5088252 ,\n",
              "        0.35029818, 0.73157256, 1.        , 0.75875861, 0.89234431])}"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "d_norm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Y53B43Pnpdg",
        "outputId": "e3f287ae-6f0c-4e8f-e97a-1ac99c95193d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'A': [0.07525231330089575,\n",
              "  0.11110993247250554,\n",
              "  1.0,\n",
              "  0.10085171430385075,\n",
              "  0.3362586030378956,\n",
              "  0.08589557098930195,\n",
              "  0.3166716257763159,\n",
              "  0.07845695355133557,\n",
              "  0.29558950944630463,\n",
              "  0.0,\n",
              "  0.17264524667274148,\n",
              "  0.02519795885608285,\n",
              "  0.21399362066317887,\n",
              "  0.20352855444366297,\n",
              "  0.315091708147771],\n",
              " 'C': [0.0,\n",
              "  0.7495696809258403,\n",
              "  0.07865597242639141,\n",
              "  1.0,\n",
              "  0.7627030301724574,\n",
              "  0.8168259804237982,\n",
              "  0.4333259554067372,\n",
              "  0.16777058828085453,\n",
              "  0.33203232126086285,\n",
              "  0.5724424696175718,\n",
              "  0.4816359939467978,\n",
              "  0.39170914029908754,\n",
              "  0.4294503690415155,\n",
              "  0.37686420256824266,\n",
              "  0.3449489815613006],\n",
              " 'D': [1.0,\n",
              "  0.25640988772162693,\n",
              "  0.32592183369372396,\n",
              "  0.4200305281353341,\n",
              "  0.5744582792254195,\n",
              "  0.1560420670881465,\n",
              "  0.0,\n",
              "  0.3091207506859722,\n",
              "  0.258039340323857,\n",
              "  0.2882727977487466,\n",
              "  0.3895335207450628,\n",
              "  0.38763175831637187,\n",
              "  0.18676139620557258,\n",
              "  0.5451097643479257,\n",
              "  0.2696370438467982],\n",
              " 'E': [1.0,\n",
              "  0.0,\n",
              "  0.8519057393700852,\n",
              "  0.4383574918534277,\n",
              "  0.8599244246079534,\n",
              "  0.44531872514061677,\n",
              "  0.34420016307077556,\n",
              "  0.419059344611419,\n",
              "  0.42225745162953326,\n",
              "  0.5198370169967937,\n",
              "  0.5156048873805594,\n",
              "  0.43016470999442546,\n",
              "  0.6900729995633731,\n",
              "  0.35120051609907876,\n",
              "  0.5345244192415937],\n",
              " 'F': [0.0,\n",
              "  0.895733473148773,\n",
              "  0.7011590523747511,\n",
              "  0.7376751135070108,\n",
              "  0.8326948911199726,\n",
              "  0.6656336257964081,\n",
              "  0.8350784673036493,\n",
              "  0.9640613943974748,\n",
              "  0.8036733026826525,\n",
              "  0.7859090504395838,\n",
              "  1.0,\n",
              "  0.9471968615621887,\n",
              "  0.866915547211168,\n",
              "  0.7070806796148316,\n",
              "  0.5571209609523142],\n",
              " 'G': [0.8429478606727597,\n",
              "  1.0,\n",
              "  0.5252595800001968,\n",
              "  0.5157339382265325,\n",
              "  0.10595183977026666,\n",
              "  0.0,\n",
              "  0.5182939879393725,\n",
              "  0.1448507683832697,\n",
              "  0.1635863707059629,\n",
              "  0.25771403489247624,\n",
              "  0.2645076978972347,\n",
              "  0.29169149364768643,\n",
              "  0.3371516858971288,\n",
              "  0.2885992645132769,\n",
              "  0.26336986042163396],\n",
              " 'H': [0.5126265387855812,\n",
              "  0.09731129383041622,\n",
              "  0.05945794084348342,\n",
              "  0.7097374700756438,\n",
              "  0.5516277849080972,\n",
              "  0.440047129202897,\n",
              "  0.7575343571408631,\n",
              "  1.0,\n",
              "  0.2820940753373731,\n",
              "  0.37571029661074035,\n",
              "  0.5913471743406188,\n",
              "  0.0,\n",
              "  0.5314019560074463,\n",
              "  0.5542149644707269,\n",
              "  0.44494028619636306],\n",
              " 'I': [0.0,\n",
              "  1.0,\n",
              "  0.9885681993705422,\n",
              "  0.6916893496569098,\n",
              "  0.716811876392177,\n",
              "  0.8904204716744661,\n",
              "  0.6644952019940336,\n",
              "  0.8546040454511806,\n",
              "  0.6913489478662816,\n",
              "  0.9061621665512967,\n",
              "  0.7032972461385075,\n",
              "  0.7838413537916215,\n",
              "  0.6408050606795745,\n",
              "  0.7634954867765327,\n",
              "  0.8904188104131613],\n",
              " 'K': [1.0,\n",
              "  0.0,\n",
              "  0.6224925689412456,\n",
              "  0.45870440453940453,\n",
              "  0.28653953182045644,\n",
              "  0.5702684748742254,\n",
              "  0.7109431777333735,\n",
              "  0.4731589744266013,\n",
              "  0.5944542049205196,\n",
              "  0.8774963904168196,\n",
              "  0.4232781906968988,\n",
              "  0.47385438071969777,\n",
              "  0.468590598677312,\n",
              "  0.654037749694505,\n",
              "  0.4283132649572589],\n",
              " 'L': [0.0,\n",
              "  0.5863803144325149,\n",
              "  1.0,\n",
              "  0.4159670626311591,\n",
              "  0.5589965160251994,\n",
              "  0.5314191618685169,\n",
              "  0.6273477703452663,\n",
              "  0.6163358349171919,\n",
              "  0.6702660421447921,\n",
              "  0.735795072378089,\n",
              "  0.838109980309614,\n",
              "  0.685712646619566,\n",
              "  0.6476918286577013,\n",
              "  0.6418595735475899,\n",
              "  0.5893267664779259],\n",
              " 'M': [0.0,\n",
              "  0.43830909825218134,\n",
              "  0.7409924383569062,\n",
              "  0.7752214270749493,\n",
              "  0.9899826728151006,\n",
              "  0.6396972425149291,\n",
              "  1.0,\n",
              "  0.8187826178008332,\n",
              "  0.6091062409752325,\n",
              "  0.5341964995888923,\n",
              "  0.5133901381085172,\n",
              "  0.9538346486338766,\n",
              "  0.6032724826669291,\n",
              "  0.8040070758905902,\n",
              "  0.7631196336148462],\n",
              " 'N': [1.0,\n",
              "  0.33875792059923404,\n",
              "  0.08051659481278953,\n",
              "  0.5409271544498805,\n",
              "  0.17196565841462272,\n",
              "  0.08031021902130163,\n",
              "  0.18874324146258997,\n",
              "  0.5291298621814148,\n",
              "  0.3042291274231407,\n",
              "  0.46516048086757544,\n",
              "  0.3558216551514157,\n",
              "  0.38102091917816505,\n",
              "  0.07103751169386222,\n",
              "  0.0,\n",
              "  0.4581217601781321],\n",
              " 'P': [1.0,\n",
              "  0.9678299346937969,\n",
              "  0.2873103002501223,\n",
              "  0.0,\n",
              "  0.7213204128707134,\n",
              "  0.6669596159543625,\n",
              "  0.6238994283073512,\n",
              "  0.5410672692796757,\n",
              "  0.5174577603260793,\n",
              "  0.5575554186175415,\n",
              "  0.5478805598359968,\n",
              "  0.5318649596881818,\n",
              "  0.5240640632391992,\n",
              "  0.5380705357967374,\n",
              "  0.5510302557034584],\n",
              " 'Q': [1.0,\n",
              "  0.0,\n",
              "  0.4874090946271054,\n",
              "  0.5245669212057058,\n",
              "  0.5793156314297405,\n",
              "  0.6777278493076948,\n",
              "  0.59227066691311,\n",
              "  0.5537248504715857,\n",
              "  0.56634213135494,\n",
              "  0.5260065313635187,\n",
              "  0.16170176261684477,\n",
              "  0.7576206204257647,\n",
              "  0.6703503929841057,\n",
              "  0.3572468087354067,\n",
              "  0.4211125451159518],\n",
              " 'R': [1.0,\n",
              "  0.0,\n",
              "  0.4038784221987408,\n",
              "  0.5654030339035435,\n",
              "  0.19358241833934803,\n",
              "  0.9218071081013374,\n",
              "  0.706684933100523,\n",
              "  0.386763003529879,\n",
              "  0.4859773194257129,\n",
              "  0.35364725786412415,\n",
              "  0.853611611157344,\n",
              "  0.6896935049070329,\n",
              "  0.5301256891869882,\n",
              "  0.5887127624896037,\n",
              "  0.6865122676206136],\n",
              " 'S': [1.0,\n",
              "  0.6629241425186176,\n",
              "  0.3971421939093515,\n",
              "  0.4420408948983864,\n",
              "  0.0,\n",
              "  0.35348655089863573,\n",
              "  0.10502055773770015,\n",
              "  0.4208554468348848,\n",
              "  0.6207996317227813,\n",
              "  0.13490123847412938,\n",
              "  0.24598842050611336,\n",
              "  0.2738604526326865,\n",
              "  0.28816462866556675,\n",
              "  0.272696218428129,\n",
              "  0.2747925450248808],\n",
              " 'T': [0.8228897134291544,\n",
              "  0.8757819027580704,\n",
              "  0.548406058063984,\n",
              "  0.577890595088464,\n",
              "  0.11999907040692198,\n",
              "  0.8861660541899355,\n",
              "  0.12255981142787364,\n",
              "  0.6162292045627772,\n",
              "  1.0,\n",
              "  0.0,\n",
              "  0.24006222576062317,\n",
              "  0.363306898053537,\n",
              "  0.4381127078433509,\n",
              "  0.3984490011957435,\n",
              "  0.1322066508263117],\n",
              " 'V': [0.0,\n",
              "  0.920716874525087,\n",
              "  1.0,\n",
              "  0.655058838720571,\n",
              "  0.5129696990389304,\n",
              "  0.9256144269570291,\n",
              "  0.48287391494469567,\n",
              "  0.6664471681991371,\n",
              "  0.5707851059690189,\n",
              "  0.6585185784388967,\n",
              "  0.5579245811081751,\n",
              "  0.5283973596348936,\n",
              "  0.6384838576643221,\n",
              "  0.6959231163231407,\n",
              "  0.718506279249867],\n",
              " 'W': [0.0,\n",
              "  0.5265518403635485,\n",
              "  0.10646350556584966,\n",
              "  0.656785011442361,\n",
              "  0.7917551877840969,\n",
              "  0.3508570096499505,\n",
              "  0.7139502832159056,\n",
              "  0.41973735777416,\n",
              "  1.0,\n",
              "  0.6448022714666447,\n",
              "  0.649460142439607,\n",
              "  0.5420991485613023,\n",
              "  0.6099816370257962,\n",
              "  0.6580120762938598,\n",
              "  0.7509510362085703],\n",
              " 'Y': [0.2345055512181357,\n",
              "  0.6856921147807877,\n",
              "  0.0,\n",
              "  0.5591293461222061,\n",
              "  0.26547243642931984,\n",
              "  0.4531111785071339,\n",
              "  0.3695535713604565,\n",
              "  0.6538405771977889,\n",
              "  0.4928710738587172,\n",
              "  0.6945165385130224,\n",
              "  0.545421988640566,\n",
              "  0.7303338734901412,\n",
              "  1.0,\n",
              "  0.776257903904405,\n",
              "  0.764500006812323]}"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    }
  ]
}